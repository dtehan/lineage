---
phase: 23-testing-and-validation
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - lineage-api/internal/adapter/inbound/http/openlineage_handlers_test.go
  - lineage-ui/src/__tests__/performance/hoverHighlight.bench.ts
autonomous: true

must_haves:
  truths:
    - "Go handler returns 200 with statistics JSON for a known dataset"
    - "Go handler returns 200 with DDL JSON for a known dataset"
    - "Go handler returns 404 for missing dataset on statistics endpoint"
    - "Go handler returns 404 for missing dataset on DDL endpoint"
    - "Go handler returns 500 with generic error (no sensitive data) when repository errors"
    - "Hover highlight computation benchmarks run for 100 and 200 node graphs"
    - "Benchmark measures relative scaling (200 nodes vs 100 nodes)"
  artifacts:
    - path: "lineage-api/internal/adapter/inbound/http/openlineage_handlers_test.go"
      provides: "Go handler tests for statistics and DDL endpoints (TEST-05)"
      min_lines: 120
    - path: "lineage-ui/src/__tests__/performance/hoverHighlight.bench.ts"
      provides: "Performance benchmarks for hover highlight computation (TEST-04)"
      min_lines: 60
  key_links:
    - from: "openlineage_handlers_test.go"
      to: "openlineage_handlers.go"
      via: "mock repository + httptest + Chi URL params"
      pattern: "olHandler\\.Get(DatasetStatistics|DatasetDDL)"
    - from: "openlineage_handlers_test.go"
      to: "mocks/repositories.go"
      via: "MockOpenLineageRepository with Statistics/DDLData maps and error injection"
      pattern: "mocks\\.NewMockOpenLineageRepository"
    - from: "hoverHighlight.bench.ts"
      to: "fixtures/graphGenerators.ts"
      via: "generateGraph for test data"
      pattern: "generateGraph\\(100\\)"
---

<objective>
Add Go backend API tests for statistics and DDL endpoints (TEST-05) and performance benchmarks for hover highlight computation on 100+ node graphs (TEST-04).

Purpose: Verify the statistics and DDL API endpoints handle success, not-found, and error cases correctly (including security -- no sensitive data in error responses). Benchmark hover highlight computation to establish baseline performance metrics for large graphs.

Output: Go handler test file for OpenLineage endpoints, and a Vitest bench file for hover performance.
</objective>

<execution_context>
@/Users/Daniel.Tehan/.claude/get-shit-done/workflows/execute-plan.md
@/Users/Daniel.Tehan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/23-testing-&-validation/23-RESEARCH.md

@lineage-api/internal/adapter/inbound/http/openlineage_handlers.go
@lineage-api/internal/adapter/inbound/http/handlers_test.go
@lineage-api/internal/domain/mocks/repositories.go
@lineage-ui/src/__tests__/performance/graphRender.bench.ts
@lineage-ui/src/__tests__/performance/fixtures/graphGenerators.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Go handler tests for statistics and DDL endpoints (TEST-05)</name>
  <files>
    lineage-api/internal/adapter/inbound/http/openlineage_handlers_test.go
  </files>
  <action>
Create `openlineage_handlers_test.go` in `lineage-api/internal/adapter/inbound/http/` package.

**Setup helper (follows handlers_test.go pattern):**
```go
func setupOpenLineageTestHandler() (*OpenLineageHandler, *mocks.MockOpenLineageRepository) {
    olRepo := mocks.NewMockOpenLineageRepository()
    olService := application.NewOpenLineageService(olRepo)
    olHandler := NewOpenLineageHandler(olService)
    return olHandler, olRepo
}
```

Reuse `newTestRequestWithRequestID` from handlers_test.go (same package, so accessible).

**Statistics endpoint tests:**
1. `TestGetDatasetStatistics_Success` -- Set olRepo.Statistics["ns1/sales_db.customers"] with SourceType="TABLE", CreatorName="admin", RowCount=ptr(int64(1500)), SizeBytes=ptr(int64(52428800)). Call handler. Assert 200, JSON response contains sourceType="TABLE", creatorName="admin", rowCount=1500.
2. `TestGetDatasetStatistics_ViewSuccess` -- Same but SourceType="VIEW", SizeBytes=nil (views have null size). Assert sourceType="VIEW".
3. `TestGetDatasetStatistics_NotFound` -- Don't set any statistics data. Call handler with "nonexistent" datasetId. Assert 404.
4. `TestGetDatasetStatistics_InternalError` -- Set olRepo.GetDatasetStatisticsErr = errors.New("db connection failed"). Assert 500. Assert response body contains "Internal server error" and does NOT contain "db connection failed" or any sensitivePatterns.
5. `TestGetDatasetStatistics_URLDecoding` -- Use URL-encoded datasetId ("ns1%2Fsales_db.customers"). Assert handler correctly receives decoded "ns1/sales_db.customers" and returns 200.

**DDL endpoint tests:**
6. `TestGetDatasetDDL_ViewSuccess` -- Set olRepo.DDLData["ns1/analytics_db.customer_view"] with SourceType="VIEW", ViewSql="CREATE VIEW...", Truncated=false, TableComment="Summary view". Assert 200, JSON has viewSql, tableComment.
7. `TestGetDatasetDDL_TableSuccess` -- Set DDL with SourceType="TABLE", ViewSql=nil. Assert 200, viewSql is null in response.
8. `TestGetDatasetDDL_TruncatedWarning` -- Set DDL with Truncated=true. Assert 200, JSON has truncated=true.
9. `TestGetDatasetDDL_NotFound` -- No DDL data set. Assert 404.
10. `TestGetDatasetDDL_InternalError` -- Set olRepo.GetDatasetDDLErr. Assert 500. Assert generic error message, no sensitive data leaked.
11. `TestGetDatasetDDL_WithColumnComments` -- Set DDLData with ColumnComments map. Assert response includes columnComments.

**Security verification (applies to error tests #4 and #10):**
For each error response, iterate over sensitivePatterns from handlers_test.go and assert none appear in the response body. This reuses the existing sensitivePatterns variable in the same package.

Use `ptr` helper for int64 pointers: `func ptr[T any](v T) *T { return &v }` -- or define a local `ptrInt64` if generics not available in Go version used.

All assertions use testify/assert and testify/require.
  </action>
  <verify>
Run: `cd /Users/Daniel.Tehan/Code/lineage/lineage-api && go test ./internal/adapter/inbound/http/ -run "TestGetDataset" -v`
All 11 tests pass. No compilation errors.
  </verify>
  <done>
openlineage_handlers_test.go has 11 tests covering:
- Statistics: success (table), success (view), not found, internal error, URL decoding
- DDL: success (view with SQL), success (table without SQL), truncated, not found, internal error, column comments
- Security: error responses contain only generic messages, no sensitive patterns
All tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Hover highlight performance benchmarks (TEST-04)</name>
  <files>
    lineage-ui/src/__tests__/performance/hoverHighlight.bench.ts
  </files>
  <action>
Create `hoverHighlight.bench.ts` in `lineage-ui/src/__tests__/performance/` following the exact pattern from `graphRender.bench.ts`.

**What to benchmark:** The hover highlight computation -- given a node ID, traverse the adjacency map (upstream + downstream) to find all connected nodes. This is what `useLineageHighlight` does internally when a user hovers or clicks a column.

**Implementation:**

```typescript
import { bench, describe } from 'vitest';
import { generateGraph, generateLayeredGraph } from './fixtures/graphGenerators';

// Build adjacency maps from edges (simulates what useLineageHighlight does)
function buildAdjacencyMaps(edges: Array<{ source: string; target: string }>) {
  const upstream = new Map<string, Set<string>>();
  const downstream = new Map<string, Set<string>>();
  for (const edge of edges) {
    if (!upstream.has(edge.target)) upstream.set(edge.target, new Set());
    upstream.get(edge.target)!.add(edge.source);
    if (!downstream.has(edge.source)) downstream.set(edge.source, new Set());
    downstream.get(edge.source)!.add(edge.target);
  }
  return { upstream, downstream };
}

// BFS to find all connected nodes (same algorithm as highlight traversal)
function computeConnectedNodes(
  nodeId: string,
  maps: ReturnType<typeof buildAdjacencyMaps>
): Set<string> {
  const visited = new Set<string>();
  const queue = [nodeId];
  while (queue.length > 0) {
    const current = queue.pop()!;
    if (visited.has(current)) continue;
    visited.add(current);
    for (const neighbor of maps.upstream.get(current) ?? []) queue.push(neighbor);
    for (const neighbor of maps.downstream.get(current) ?? []) queue.push(neighbor);
  }
  return visited;
}
```

**Benchmark suites:**

1. "Hover Highlight Computation" describe block:
   - bench 'highlight computation 50 nodes' -- generateGraph(50), pick middle node, compute connected, { time: 5000 }
   - bench 'highlight computation 100 nodes' -- generateGraph(100), same
   - bench 'highlight computation 200 nodes' -- generateGraph(200), same

2. "Adjacency Map Construction" describe block:
   - bench 'build adjacency maps 100 nodes' -- generateGraph(100), build maps, { time: 5000 }
   - bench 'build adjacency maps 200 nodes' -- generateGraph(200), build maps, { time: 5000 }

3. "Deep Graph Highlight" describe block:
   - bench 'highlight on deep graph (20 layers x 5 wide)' -- generateLayeredGraph(20, 5), compute connected from first node, { time: 5000 }
   - bench 'highlight on wide graph (5 layers x 20 wide)' -- generateLayeredGraph(5, 20), same

Add file header comment explaining these measure React computation time not browser render time, consistent with existing bench files. Note that values are for relative comparison (regression detection), not absolute performance targets.

Pre-generate graphs outside bench callbacks to avoid including generation time in measurements.
  </action>
  <verify>
Run: `cd /Users/Daniel.Tehan/Code/lineage/lineage-ui && npx vitest bench src/__tests__/performance/hoverHighlight.bench.ts --run`
Benchmarks complete without errors. Output shows ops/sec for each benchmark.
  </verify>
  <done>
hoverHighlight.bench.ts has 7 benchmarks across 3 suites:
- Highlight computation at 50, 100, 200 nodes
- Adjacency map construction at 100, 200 nodes
- Deep vs wide graph highlight comparison
Benchmarks run successfully and produce measurable ops/sec output.
  </done>
</task>

</tasks>

<verification>
Run Go tests:
```bash
cd /Users/Daniel.Tehan/Code/lineage/lineage-api && go test ./internal/adapter/inbound/http/ -v
```
All Go handler tests pass (existing + new).

Run frontend benchmarks:
```bash
cd /Users/Daniel.Tehan/Code/lineage/lineage-ui && npx vitest bench --run
```
All benchmarks complete (existing + new).
</verification>

<success_criteria>
- TEST-05 satisfied: 11 Go handler tests cover statistics and DDL endpoints (success, 404, 500, security)
- TEST-04 satisfied: 7 benchmarks measure hover highlight computation for 50-200 node graphs
- No sensitive data exposed in error response tests
- All existing tests still pass
</success_criteria>

<output>
After completion, create `.planning/phases/23-testing-&-validation/23-02-SUMMARY.md`
</output>
