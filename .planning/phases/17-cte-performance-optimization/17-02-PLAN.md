---
phase: 17-cte-performance-optimization
plan: 02
type: execute
wave: 2
depends_on: ["17-01"]
files_modified:
  - lineage-api/internal/adapter/outbound/teradata/openlineage_repo.go
  - database/benchmark_results.md
autonomous: true

must_haves:
  truths:
    - "Optimizations applied to identified bottlenecks"
    - "Post-optimization benchmarks show improvement at depth > 10"
    - "Query hints evaluated for Teradata optimization"
    - "Regression tests pass after optimization"
  artifacts:
    - path: "lineage-api/internal/adapter/outbound/teradata/openlineage_repo.go"
      provides: "Optimized CTE queries"
      exports: ["GetColumnLineage", "buildUpstreamQuery", "buildDownstreamQuery"]
    - path: "database/benchmark_results.md"
      provides: "Pre and post optimization comparison"
      contains: "## Post-Optimization Results"
  key_links:
    - from: "database/benchmark_cte.py"
      to: "lineage-api/internal/adapter/outbound/teradata/openlineage_repo.go"
      via: "Same CTE patterns"
      pattern: "WITH RECURSIVE"
---

<objective>
Apply optimizations to CTE queries based on identified bottlenecks and verify performance improvements.

Purpose: Improve recursive CTE performance at depths > 10 while maintaining correctness for cycles, diamonds, and fan patterns.

Output:
- Optimized CTE queries in `openlineage_repo.go`
- Updated `benchmark_results.md` with post-optimization comparison
</objective>

<execution_context>
@/Users/Daniel.Tehan/.claude/get-shit-done/workflows/execute-plan.md
@/Users/Daniel.Tehan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/17-cte-performance-optimization/17-01-SUMMARY.md
@lineage-api/internal/adapter/outbound/teradata/openlineage_repo.go
@specs/coding_standards_sql.md (Teradata optimization patterns)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Apply CTE optimizations</name>
  <files>lineage-api/internal/adapter/outbound/teradata/openlineage_repo.go</files>
  <action>
Based on bottlenecks identified in Plan 01, apply optimizations to the CTE queries.

**Optimization Candidates** (evaluate each based on Plan 01 findings):

1. **LOCKING hint for read-heavy queries** (PERF-CTE-05):
   - Add `LOCKING ROW FOR ACCESS` to the CTE queries
   - This allows dirty reads but prevents lock contention
   - Pattern: Prefix query with `LOCKING TABLE demo_user.OL_COLUMN_LINEAGE FOR ACCESS`

2. **Optimize path string handling**:
   - Current: `CAST(l.lineage_id AS VARCHAR(4000))` concatenated with `||`
   - Option A: Use shorter VARCHAR if lineage_id max length is known
   - Option B: Use HASHROW for cycle detection instead of POSITION (evaluate if Teradata supports)

3. **Reduce columns in recursive part**:
   - Only select columns needed for recursion in the CTE itself
   - Move full column selection to final SELECT
   - This reduces spool size per row

4. **Add query hints if beneficial**:
   ```sql
   /*+ NO_STEP_PARALLELISM */  -- If AMP skew is an issue
   /*+ MERGE */                 -- Force merge join if hash join is slow
   ```
   Note: Teradata query hints syntax differs from other databases - verify syntax

5. **Consider materialized path approach** (if path lookup is the bottleneck):
   - Store visited nodes in a separate derived table
   - Use EXISTS check instead of POSITION

**Implementation approach**:

For the upstream query builder (`buildUpstreamQuery`):
```go
func (r *OpenLineageRepository) buildUpstreamQuery(maxDepth int) string {
    return fmt.Sprintf(`
        LOCKING TABLE demo_user.OL_COLUMN_LINEAGE FOR ACCESS
        WITH RECURSIVE lineage_path (
            lineage_id, run_id, source_namespace, source_dataset, source_field,
            target_namespace, target_dataset, target_field,
            transformation_type, transformation_subtype, transformation_description,
            masking, confidence_score, discovered_at, is_active, depth, path
        ) AS (
            -- Base case: direct upstream of target
            SELECT
                l.lineage_id, l.run_id, l.source_namespace, l.source_dataset, l.source_field,
                l.target_namespace, l.target_dataset, l.target_field,
                l.transformation_type, l.transformation_subtype, l.transformation_description,
                l.masking, l.confidence_score, l.discovered_at, l.is_active,
                1 AS depth,
                CAST(l.lineage_id AS VARCHAR(4000)) AS path
            FROM demo_user.OL_COLUMN_LINEAGE l
            WHERE l.target_dataset = ? AND l.target_field = ? AND l.is_active = 'Y'

            UNION ALL

            -- Recursive case: traverse upstream
            SELECT
                l.lineage_id, l.run_id, l.source_namespace, l.source_dataset, l.source_field,
                l.target_namespace, l.target_dataset, l.target_field,
                l.transformation_type, l.transformation_subtype, l.transformation_description,
                l.masking, l.confidence_score, l.discovered_at, l.is_active,
                lp.depth + 1,
                lp.path || ',' || l.lineage_id
            FROM demo_user.OL_COLUMN_LINEAGE l
            INNER JOIN lineage_path lp
                ON l.target_dataset = lp.source_dataset
                AND l.target_field = lp.source_field
            WHERE l.is_active = 'Y'
                AND lp.depth < %d
                AND POSITION(l.lineage_id IN lp.path) = 0
        )
        SELECT DISTINCT
            lineage_id, run_id, source_namespace, source_dataset, source_field,
            target_namespace, target_dataset, target_field,
            transformation_type, transformation_subtype, transformation_description,
            masking, confidence_score, discovered_at, is_active, depth
        FROM lineage_path
        ORDER BY depth`, maxDepth)
}
```

Apply the same pattern to `buildDownstreamQuery` and `buildBidirectionalQuery`.

**IMPORTANT**: Only apply optimizations that:
- Are supported by Teradata syntax
- Don't break cycle detection (CORRECT-VAL-01 must still pass)
- Show measurable improvement in Plan 01 benchmarks

If Plan 01 shows no significant bottlenecks at depth 20, document that the current implementation is acceptable and make minimal changes (just adding LOCKING hint if beneficial).
  </action>
  <verify>
1. Run Go tests: `cd lineage-api && go test ./internal/adapter/outbound/teradata/... -v`
2. Run correctness tests: `cd database && python test_correctness.py`
Both must pass to ensure optimizations don't break functionality.
  </verify>
  <done>
CTE queries optimized with identified improvements while maintaining correctness for all graph patterns.
  </done>
</task>

<task type="auto">
  <name>Task 2: Run post-optimization benchmarks and document comparison</name>
  <files>database/benchmark_results.md</files>
  <action>
Re-run benchmarks after optimization and document the comparison:

1. **Run the same benchmark suite**:
   ```bash
   cd database && python benchmark_cte.py
   ```

2. **Update benchmark_results.md** with:

   a) **Post-Optimization Results** section:
      | Dataset | Direction | Depth | Min (ms) | Avg (ms) | Max (ms) | Rows | Notes |

   b) **Performance Comparison** table:
      | Metric | Before | After | Improvement |
      |--------|--------|-------|-------------|
      | Depth 10 avg (ms) | X | Y | Z% |
      | Depth 15 avg (ms) | X | Y | Z% |
      | Depth 20 avg (ms) | X | Y | Z% |

   c) **Optimization Impact Analysis**:
      - Which optimizations had the most impact
      - Any optimizations that didn't help
      - Teradata-specific findings

   d) **Final Recommendations**:
      - Recommended max depth setting for production
      - Any additional optimizations to consider for future

3. **Verify PERF-CTE requirements**:
   - PERF-CTE-01: Benchmarks at depths 5, 10, 15, 20 documented (Plan 01 + this task)
   - PERF-CTE-02: Bottlenecks identified (Plan 01)
   - PERF-CTE-03: Optimizations applied (Task 1)
   - PERF-CTE-04: Improvement verified at depth > 10 (this task)
   - PERF-CTE-05: Query hints evaluated (Task 1)

If database is unavailable or optimizations show no improvement:
- Document the findings honestly
- Note that the current implementation is acceptable
- Provide recommendations for future optimization if performance issues arise
  </action>
  <verify>
Check that benchmark_results.md contains:
- Post-optimization results table
- Performance comparison with improvement percentages
- Final recommendations section
  </verify>
  <done>
Post-optimization benchmarks documented showing improvement at depth > 10, or documented justification if no significant improvement was needed.
  </done>
</task>

</tasks>

<verification>
1. `cd lineage-api && go test ./internal/adapter/outbound/teradata/... -v` passes
2. `cd database && python test_correctness.py` passes (16/16 tests)
3. `database/benchmark_results.md` contains post-optimization comparison
4. PERF-CTE-01 through PERF-CTE-05 requirements addressed
</verification>

<success_criteria>
- CTE queries optimized based on identified bottlenecks (PERF-CTE-03)
- Post-optimization benchmarks show improvement at depth > 10 (PERF-CTE-04)
- Query hints evaluated and applied if beneficial (PERF-CTE-05)
- Correctness tests still pass (cycles, diamonds, fans)
- Clear documentation of what was optimized and the impact
</success_criteria>

<output>
After completion, create `.planning/phases/17-cte-performance-optimization/17-02-SUMMARY.md`
</output>
