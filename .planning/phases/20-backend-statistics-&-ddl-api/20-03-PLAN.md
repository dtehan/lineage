---
phase: 20-backend-statistics-and-ddl-api
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - lineage-api/python_server.py
  - lineage-api/internal/adapter/outbound/teradata/openlineage_repo.go
  - lineage-api/internal/application/openlineage_service.go
  - lineage-api/internal/domain/mocks/repositories.go
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "GET /api/v2/openlineage/datasets/demo_user.customers/statistics returns 200 with table metadata (not 404)"
    - "GET /api/v2/openlineage/datasets/demo_user.customers/ddl returns 200 with DDL info (not 404)"
    - "GET /api/v2/openlineage/datasets/{namespace_hash}/demo_user.customers/statistics still works (full dataset_id format)"
    - "GET /api/v2/openlineage/datasets/nonexistent/statistics returns 404"
    - "Existing Go handler tests still pass after changes"
  artifacts:
    - path: "lineage-api/python_server.py"
      provides: "Statistics and DDL endpoints that accept dataset name OR dataset_id"
      contains: "OR.*name"
    - path: "lineage-api/internal/adapter/outbound/teradata/openlineage_repo.go"
      provides: "Go repo queries that accept dataset name OR dataset_id"
      contains: "OR.*name"
    - path: "lineage-api/internal/application/openlineage_service.go"
      provides: "Service layer resolves dataset by ID or name, passes resolved ID downstream"
    - path: "lineage-api/internal/domain/mocks/repositories.go"
      provides: "Mock GetDataset also matches by Name field"
  key_links:
    - from: "lineage-ui/src/components/domain/LineageGraph/DetailPanel.tsx"
      to: "/api/v2/openlineage/datasets/{name}/statistics"
      via: "effectiveDatasetId (format: database.table)"
      pattern: "demo_user\\."
    - from: "python_server.py get_dataset_statistics"
      to: "OL_DATASET"
      via: "WHERE dataset_id = ? OR name = ?"
      pattern: "OR.*name"
    - from: "openlineage_repo.go GetDatasetStatistics"
      to: "OL_DATASET"
      via: "WHERE dataset_id = ? OR name = ?"
      pattern: "OR.*\"name\""
---

<objective>
Fix dataset ID format mismatch causing 404 errors on statistics and DDL endpoints.

Purpose: The frontend sends dataset names (format: "database.table") but the backend queries OL_DATASET.dataset_id which stores "{namespace_hash}/database.table". This mismatch causes every statistics and DDL request to return 404, blocking all 9 UAT tests (tests 1-4 directly, tests 5-9 indirectly).

Output: Both Python and Go backends accept either dataset_id OR dataset name as the lookup key, resolving the 404 errors.
</objective>

<execution_context>
@/Users/Daniel.Tehan/.claude/get-shit-done/workflows/execute-plan.md
@/Users/Daniel.Tehan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/20-backend-statistics-&-ddl-api/20-01-SUMMARY.md
@.planning/phases/20-backend-statistics-&-ddl-api/20-02-SUMMARY.md
@.planning/phases/20-backend-statistics-&-ddl-api/20-UAT.md
@.planning/debug/statistics-endpoint-404.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix Python Flask statistics and DDL endpoints to accept dataset name</name>
  <files>lineage-api/python_server.py</files>
  <action>
  Modify both `get_dataset_statistics()` (line ~1697) and `get_dataset_ddl()` (line ~1787) in python_server.py.

  **For both endpoints, replace the OL_DATASET existence check query:**

  Current (line ~1703 and ~1794):
  ```python
  cur.execute("""
      SELECT source_type FROM OL_DATASET WHERE dataset_id = ?
  """, [dataset_id])
  ```

  Replace with a query that matches by dataset_id OR by name, and also retrieves the dataset_id and name so we can use the correct value for name parsing:
  ```python
  cur.execute("""
      SELECT dataset_id, "name", source_type FROM OL_DATASET
      WHERE dataset_id = ? OR "name" = ?
  """, [dataset_id, dataset_id])
  ```

  After fetching ds_row, extract the resolved values:
  ```python
  ds_row = cur.fetchone()
  if not ds_row:
      return jsonify({"error": "Dataset not found"}), 404
  resolved_dataset_id = ds_row[0]
  resolved_name = ds_row[1]
  ```

  **Then fix the name parsing to use `resolved_name` instead of `dataset_id`:**

  Current (line ~1712 and ~1802):
  ```python
  name_part = dataset_id.split("/", 1)[1] if "/" in dataset_id else dataset_id
  ```

  Replace with:
  ```python
  name_part = resolved_name.strip() if resolved_name else (dataset_id.split("/", 1)[1] if "/" in dataset_id else dataset_id)
  ```

  This way: if the input is "demo_user.customers" (name format), the OR clause matches on `name`, we get the row, and `resolved_name` = "demo_user.customers" is used for parsing. If the input is "abc123/demo_user.customers" (full dataset_id format), the OR clause matches on `dataset_id`, we get the row, and `resolved_name` = "demo_user.customers" is still used for parsing.

  **Also update the `result["datasetId"]` to use `resolved_dataset_id`** (not the input parameter) so the response always contains the canonical dataset_id:
  - In statistics: `result["datasetId"] = resolved_dataset_id` (around line ~1740)
  - In DDL: `result["datasetId"] = resolved_dataset_id` (around line ~1863)

  Important: The `"name"` column name in SQL must be quoted (it is a reserved word in Teradata). Use double quotes: `"name"`.
  </action>
  <verify>
  Start the Python server and test both formats:
  ```bash
  cd /Users/Daniel.Tehan/Code/lineage/lineage-api
  # Start server in background, test, then stop
  # Or use curl against running server if already up
  curl -s http://localhost:8080/api/v2/openlineage/datasets/demo_user.SRC_CUSTOMERS/statistics | python3 -m json.tool
  curl -s http://localhost:8080/api/v2/openlineage/datasets/demo_user.SRC_CUSTOMERS/ddl | python3 -m json.tool
  ```
  Both should return 200 with JSON data (not 404).
  </verify>
  <done>
  - Statistics endpoint returns 200 with rowCount, sizeBytes, sourceType etc. when called with dataset name format ("database.table")
  - DDL endpoint returns 200 with viewSql/tableComment/columnComments when called with dataset name format
  - Both endpoints still work with full dataset_id format ("namespace_hash/database.table")
  - 404 still returned for genuinely nonexistent datasets
  - 500 errors still return generic "Internal server error" (no SQL leak)
  </done>
</task>

<task type="auto">
  <name>Task 2: Fix Go backend to accept dataset name across service, repository, and mock layers</name>
  <files>
    lineage-api/internal/application/openlineage_service.go
    lineage-api/internal/adapter/outbound/teradata/openlineage_repo.go
    lineage-api/internal/domain/mocks/repositories.go
  </files>
  <action>
  The Go backend has a 3-layer fix needed: service, repository, and mock.

  **A. Fix `GetDataset` in openlineage_repo.go (line ~118):**

  Change the query from:
  ```go
  query := `
      SELECT dataset_id, namespace_id, name, description, source_type, created_at, updated_at, is_active
      FROM demo_user.OL_DATASET
      WHERE dataset_id = ?`
  ```
  To:
  ```go
  query := `
      SELECT dataset_id, namespace_id, name, description, source_type, created_at, updated_at, is_active
      FROM demo_user.OL_DATASET
      WHERE dataset_id = ? OR "name" = ?`
  ```
  And pass both params: `r.db.QueryRowContext(ctx, query, datasetID, datasetID).Scan(...)`

  **B. Fix `GetDatasetStatistics` existence check in openlineage_repo.go (line ~816):**

  Change:
  ```go
  existsQuery := `SELECT dataset_id FROM demo_user.OL_DATASET WHERE dataset_id = ?`
  var exists string
  err := r.db.QueryRowContext(ctx, existsQuery, datasetID).Scan(&exists)
  ```
  To:
  ```go
  existsQuery := `SELECT dataset_id, "name" FROM demo_user.OL_DATASET WHERE dataset_id = ? OR "name" = ?`
  var resolvedID, resolvedName string
  err := r.db.QueryRowContext(ctx, existsQuery, datasetID, datasetID).Scan(&resolvedID, &resolvedName)
  ```
  Then use `resolvedName` instead of `datasetID` for `parseDatasetName`:
  ```go
  dbName, tableName, err := parseDatasetName(resolvedName)
  ```
  And set `stats.DatasetID = resolvedID` so the response has the canonical ID.

  **C. Fix `GetDatasetDDL` existence check in openlineage_repo.go (line ~910):**

  Same pattern as B:
  ```go
  existsQuery := `SELECT dataset_id, "name" FROM demo_user.OL_DATASET WHERE dataset_id = ? OR "name" = ?`
  var resolvedID, resolvedName string
  err := r.db.QueryRowContext(ctx, existsQuery, datasetID, datasetID).Scan(&resolvedID, &resolvedName)
  ```
  Use `resolvedName` for `parseDatasetName`, and `resolvedID` for `ddl.DatasetID`.

  **D. Fix `parseDatasetName` helper (line ~780):**

  Currently errors if no "/" found. Change to handle name-only format:
  ```go
  func parseDatasetName(nameOrID string) (database, table string, err error) {
      // Extract the name portion: either after "/" for dataset_id format, or use as-is for name format
      name := nameOrID
      if slashIdx := strings.LastIndex(nameOrID, "/"); slashIdx >= 0 {
          name = nameOrID[slashIdx+1:]
      }

      dotIdx := strings.Index(name, ".")
      if dotIdx < 0 {
          return "", "", fmt.Errorf("invalid dataset name format: missing '.'")
      }

      database = strings.TrimSpace(name[:dotIdx])
      table = strings.TrimSpace(name[dotIdx+1:])
      if database == "" || table == "" {
          return "", "", fmt.Errorf("invalid dataset name: empty database or table")
      }
      return database, table, nil
  }
  ```

  **E. Fix `GetDataset` in mock repositories.go (line ~574):**

  Currently only matches by ID. Add name fallback:
  ```go
  func (m *MockOpenLineageRepository) GetDataset(ctx context.Context, datasetID string) (*domain.OpenLineageDataset, error) {
      m.mu.RLock()
      defer m.mu.RUnlock()
      if m.GetDatasetErr != nil {
          return nil, m.GetDatasetErr
      }
      for i := range m.Datasets {
          if m.Datasets[i].ID == datasetID || m.Datasets[i].Name == datasetID {
              return &m.Datasets[i], nil
          }
      }
      return nil, nil
  }
  ```

  **F. Fix service layer (openlineage_service.go lines ~156 and ~198):**

  The service calls `s.repo.GetDataset(ctx, datasetID)` for existence check, then passes `datasetID` to `s.repo.GetDatasetStatistics(ctx, datasetID)`. After the GetDataset fix (step A), the returned dataset object has the canonical `ds.ID`. Pass this resolved ID to the stats/DDL repo call:

  In `GetDatasetStatistics` (line ~166):
  ```go
  stats, err := s.repo.GetDatasetStatistics(ctx, ds.ID)
  ```
  (changed from `datasetID` to `ds.ID`)

  In `GetDatasetDDL` (line ~208):
  ```go
  ddl, err := s.repo.GetDatasetDDL(ctx, ds.ID)
  ```
  (changed from `datasetID` to `ds.ID`)

  This way even if the input was a name, the repo methods get the canonical dataset_id.

  **After all changes, run the Go handler tests to confirm they still pass:**
  ```bash
  cd /Users/Daniel.Tehan/Code/lineage/lineage-api && go test ./internal/adapter/inbound/http/ -run "TestGetDataset(Statistics|DDL)" -v
  ```
  </action>
  <verify>
  ```bash
  cd /Users/Daniel.Tehan/Code/lineage/lineage-api && go test ./internal/... -v -count=1 2>&1 | tail -30
  ```
  All existing tests pass. Specifically the TestGetDatasetStatistics_* and TestGetDatasetDDL_* tests must all pass.
  </verify>
  <done>
  - Go `GetDataset` repo method matches by dataset_id OR name
  - Go `GetDatasetStatistics` repo method resolves name to dataset_id before querying DBC views
  - Go `GetDatasetDDL` repo method resolves name to dataset_id before querying DBC views
  - `parseDatasetName` handles both "namespace/database.table" and "database.table" formats
  - Mock `GetDataset` matches by ID or Name for test compatibility
  - Service layer passes resolved dataset ID (not raw input) to repo methods
  - All existing Go handler tests pass without modification
  </done>
</task>

</tasks>

<verification>
1. Start the Python server and verify statistics endpoint works with name format:
   ```bash
   curl -s http://localhost:8080/api/v2/openlineage/datasets/demo_user.SRC_CUSTOMERS/statistics
   ```
   Expected: 200 with JSON containing rowCount, sourceType, etc.

2. Verify DDL endpoint works with name format:
   ```bash
   curl -s http://localhost:8080/api/v2/openlineage/datasets/demo_user.SRC_CUSTOMERS/ddl
   ```
   Expected: 200 with JSON containing tableComment, columnComments, etc.

3. Verify 404 still works for genuinely missing datasets:
   ```bash
   curl -s -o /dev/null -w "%{http_code}" http://localhost:8080/api/v2/openlineage/datasets/nonexistent_db.nonexistent_table/statistics
   ```
   Expected: 404

4. Run Go tests:
   ```bash
   cd /Users/Daniel.Tehan/Code/lineage/lineage-api && go test ./internal/... -count=1
   ```
   Expected: All tests pass

5. Open the UI, navigate to a table in database lineage view, click to open detail panel, switch to Statistics tab -- data loads instead of error.
</verification>

<success_criteria>
- Statistics and DDL endpoints return 200 when called with dataset name format ("database.table")
- Both endpoints still work with full dataset_id format ("namespace_hash/database.table")
- 404 returned for genuinely nonexistent datasets
- All existing Go handler tests pass
- UAT tests 1-4 (statistics/DDL functionality) are unblocked
- UAT tests 5-9 (error handling) can be retested for verification
</success_criteria>

<output>
After completion, create `.planning/phases/20-backend-statistics-&-ddl-api/20-03-SUMMARY.md`
</output>
