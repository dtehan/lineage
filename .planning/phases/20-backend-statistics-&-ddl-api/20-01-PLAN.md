---
phase: 20-backend-statistics-and-ddl-api
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - lineage-api/internal/domain/entities.go
  - lineage-api/internal/domain/repository.go
  - lineage-api/internal/application/dto.go
  - lineage-api/internal/application/openlineage_service.go
  - lineage-api/internal/adapter/outbound/teradata/openlineage_repo.go
  - lineage-api/internal/adapter/inbound/http/openlineage_handlers.go
  - lineage-api/internal/adapter/inbound/http/router.go
  - lineage-api/internal/domain/mocks/repositories.go
autonomous: true

must_haves:
  truths:
    - "GET /api/v2/openlineage/datasets/{datasetId}/statistics returns row count, size, owner, dates, type for a known dataset"
    - "GET /api/v2/openlineage/datasets/{datasetId}/ddl returns view SQL, table comment, and column comments"
    - "Both endpoints return 404 for unknown dataset IDs (not 500)"
    - "Internal errors return generic 'Internal server error' (no SQL or connection details leaked)"
    - "Both tables and views return valid statistics responses (views have null sizeBytes)"
  artifacts:
    - path: "lineage-api/internal/domain/entities.go"
      provides: "DatasetStatistics and DatasetDDL domain structs"
      contains: "DatasetStatistics"
    - path: "lineage-api/internal/domain/repository.go"
      provides: "GetDatasetStatistics and GetDatasetDDL interface methods"
      contains: "GetDatasetStatistics"
    - path: "lineage-api/internal/application/dto.go"
      provides: "DatasetStatisticsResponse and DatasetDDLResponse DTOs"
      contains: "DatasetStatisticsResponse"
    - path: "lineage-api/internal/application/openlineage_service.go"
      provides: "GetDatasetStatistics and GetDatasetDDL service methods"
      contains: "GetDatasetStatistics"
    - path: "lineage-api/internal/adapter/outbound/teradata/openlineage_repo.go"
      provides: "Teradata DBC queries for statistics and DDL"
      contains: "DBC.TablesV"
    - path: "lineage-api/internal/adapter/inbound/http/openlineage_handlers.go"
      provides: "HTTP handlers for statistics and DDL endpoints"
      contains: "GetDatasetStatistics"
    - path: "lineage-api/internal/adapter/inbound/http/router.go"
      provides: "Route registrations for /statistics and /ddl"
      contains: "statistics"
    - path: "lineage-api/internal/domain/mocks/repositories.go"
      provides: "Mock implementations for new repository methods"
      contains: "GetDatasetStatistics"
  key_links:
    - from: "lineage-api/internal/adapter/inbound/http/openlineage_handlers.go"
      to: "lineage-api/internal/application/openlineage_service.go"
      via: "h.service.GetDatasetStatistics and h.service.GetDatasetDDL"
      pattern: "h\\.service\\.GetDataset(Statistics|DDL)"
    - from: "lineage-api/internal/application/openlineage_service.go"
      to: "lineage-api/internal/adapter/outbound/teradata/openlineage_repo.go"
      via: "s.repo.GetDatasetStatistics and s.repo.GetDatasetDDL"
      pattern: "s\\.repo\\.GetDataset(Statistics|DDL)"
    - from: "lineage-api/internal/adapter/outbound/teradata/openlineage_repo.go"
      to: "DBC system views"
      via: "SQL queries to DBC.TablesV, DBC.TableStatsV, DBC.TableSizeV, DBC.ColumnsJQV"
      pattern: "DBC\\.(TablesV|TableStatsV|TableSizeV|ColumnsJQV)"
    - from: "lineage-api/internal/adapter/inbound/http/router.go"
      to: "lineage-api/internal/adapter/inbound/http/openlineage_handlers.go"
      via: "route registration"
      pattern: "datasets.*statistics|datasets.*ddl"
---

<objective>
Add statistics and DDL API endpoints to the Go backend, providing table/view metadata (row count, size, owner, dates, type) and view definition SQL with comments.

Purpose: Phase 21 (Detail Panel Enhancement) needs these endpoints to display metadata in the frontend. This plan builds the complete Go backend vertical slice following the established hexagonal architecture pattern.

Output: Two new working API endpoints accessible at GET /api/v2/openlineage/datasets/{datasetId}/statistics and GET /api/v2/openlineage/datasets/{datasetId}/ddl, with proper 404/500 handling and security-compliant error responses.
</objective>

<execution_context>
@/Users/Daniel.Tehan/.claude/get-shit-done/workflows/execute-plan.md
@/Users/Daniel.Tehan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/20-backend-statistics-&-ddl-api/20-RESEARCH.md

@lineage-api/internal/domain/entities.go
@lineage-api/internal/domain/repository.go
@lineage-api/internal/application/dto.go
@lineage-api/internal/application/openlineage_service.go
@lineage-api/internal/adapter/outbound/teradata/openlineage_repo.go
@lineage-api/internal/adapter/inbound/http/openlineage_handlers.go
@lineage-api/internal/adapter/inbound/http/router.go
@lineage-api/internal/adapter/inbound/http/response.go
@lineage-api/internal/domain/mocks/repositories.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Domain entities, repository interface, DTOs, service layer, and Teradata repository</name>
  <files>
    lineage-api/internal/domain/entities.go
    lineage-api/internal/domain/repository.go
    lineage-api/internal/application/dto.go
    lineage-api/internal/application/openlineage_service.go
    lineage-api/internal/adapter/outbound/teradata/openlineage_repo.go
  </files>
  <action>
    **1. Add domain entities to entities.go** (append after existing OpenLineageEdge struct):

    ```go
    // DatasetStatistics represents metadata about a dataset's physical properties.
    type DatasetStatistics struct {
        DatasetID          string     `json:"datasetId"`
        DatabaseName       string     `json:"databaseName"`
        TableName          string     `json:"tableName"`
        SourceType         string     `json:"sourceType"`          // TABLE, VIEW
        CreatorName        string     `json:"creatorName,omitempty"`
        CreateTimestamp    *time.Time `json:"createTimestamp,omitempty"`
        LastAlterTimestamp *time.Time `json:"lastAlterTimestamp,omitempty"`
        RowCount           *int64     `json:"rowCount,omitempty"`
        SizeBytes          *int64     `json:"sizeBytes,omitempty"`
        TableComment       string     `json:"tableComment,omitempty"`
    }

    // DatasetDDL represents the definition and comments for a dataset.
    type DatasetDDL struct {
        DatasetID      string            `json:"datasetId"`
        DatabaseName   string            `json:"databaseName"`
        TableName      string            `json:"tableName"`
        SourceType     string            `json:"sourceType"`
        ViewSQL        string            `json:"viewSql,omitempty"`
        Truncated      bool              `json:"truncated"`
        TableComment   string            `json:"tableComment,omitempty"`
        ColumnComments map[string]string `json:"columnComments,omitempty"`
    }
    ```

    **2. Extend OpenLineageRepository interface in repository.go** (add to the end of the interface, before closing brace):

    ```go
    // Dataset metadata operations
    GetDatasetStatistics(ctx context.Context, datasetID string) (*DatasetStatistics, error)
    GetDatasetDDL(ctx context.Context, datasetID string) (*DatasetDDL, error)
    ```

    **3. Add DTOs to dto.go** (append after PaginatedDatasetsResponse):

    ```go
    // DatasetStatisticsResponse represents statistics in API responses
    type DatasetStatisticsResponse struct {
        DatasetID          string  `json:"datasetId"`
        DatabaseName       string  `json:"databaseName"`
        TableName          string  `json:"tableName"`
        SourceType         string  `json:"sourceType"`
        CreatorName        string  `json:"creatorName,omitempty"`
        CreateTimestamp    *string `json:"createTimestamp,omitempty"`
        LastAlterTimestamp *string `json:"lastAlterTimestamp,omitempty"`
        RowCount           *int64  `json:"rowCount,omitempty"`
        SizeBytes          *int64  `json:"sizeBytes,omitempty"`
        TableComment       string  `json:"tableComment,omitempty"`
    }

    // DatasetDDLResponse represents DDL info in API responses
    type DatasetDDLResponse struct {
        DatasetID      string            `json:"datasetId"`
        DatabaseName   string            `json:"databaseName"`
        TableName      string            `json:"tableName"`
        SourceType     string            `json:"sourceType"`
        ViewSQL        string            `json:"viewSql,omitempty"`
        Truncated      bool              `json:"truncated"`
        TableComment   string            `json:"tableComment,omitempty"`
        ColumnComments map[string]string `json:"columnComments,omitempty"`
    }
    ```
    Note: Timestamps in DTOs are `*string` (not `*time.Time`) to match the existing pattern where service layer formats times as RFC3339 strings.

    **4. Add service methods to openlineage_service.go** (append after existing GetLineageGraph method, before helper methods section):

    Add `GetDatasetStatistics` method:
    - Call `s.repo.GetDataset(ctx, datasetID)` first to verify dataset exists. If nil, return nil, nil.
    - Call `s.repo.GetDatasetStatistics(ctx, datasetID)`. If nil, return nil, nil.
    - Convert domain entity to DTO response, formatting timestamps with `.Format("2006-01-02T15:04:05Z")` (same pattern as existing datasetToResponse).

    Add `GetDatasetDDL` method:
    - Call `s.repo.GetDataset(ctx, datasetID)` first to verify dataset exists. If nil, return nil, nil.
    - Call `s.repo.GetDatasetDDL(ctx, datasetID)`. If nil, return nil, nil.
    - Convert domain entity to DTO response.

    **5. Implement Teradata repository methods in openlineage_repo.go** (append after GetColumnLineageGraph method):

    Add a helper function `parseDatasetName(datasetID string) (database, table string, err error)`:
    - Find last "/" in datasetID to split namespace_id from name.
    - Find first "." in name to split database from table.
    - Return error if format is invalid.
    - Use `strings.TrimSpace()` on both values.

    Add `GetDatasetStatistics`:
    - First verify dataset exists: `SELECT dataset_id FROM demo_user.OL_DATASET WHERE dataset_id = ?`. Return `nil, nil` if no rows.
    - Parse database and table from datasetID using parseDatasetName.
    - Query DBC.TablesV for metadata:
      ```sql
      SELECT TRIM(t.TableName), t.TableKind, TRIM(t.CreatorName),
             t.CreateTimeStamp, t.LastAlterTimeStamp, TRIM(t.CommentString)
      FROM DBC.TablesV t
      WHERE t.DatabaseName = ? AND t.TableName = ?
      ```
    - Map TableKind: 'T' -> "TABLE", 'V' -> "VIEW", 'O' -> "TABLE" (default to "TABLE" for others).
    - Query DBC.TableStatsV for row count (wrap in separate query, handle permission errors gracefully by leaving RowCount nil):
      ```sql
      SELECT RowCount FROM DBC.TableStatsV
      WHERE DatabaseName = ? AND TableName = ? AND IndexNumber = 1
      ```
    - Query DBC.TableSizeV for size (only for tables, skip for views; wrap in separate query, handle errors gracefully):
      ```sql
      SELECT SUM(CurrentPerm) FROM DBC.TableSizeV
      WHERE DatabaseName = ? AND TableName = ?
      ```
    - Use `sql.NullTime`, `sql.NullInt64`, `sql.NullString`, `sql.NullFloat64` for all DBC columns. Use `strings.TrimSpace()` on all string results from DBC.
    - Return `*DatasetStatistics` with populated fields. Nil fields (RowCount, SizeBytes, timestamps) remain nil when data unavailable.

    Add `GetDatasetDDL`:
    - First verify dataset exists: `SELECT dataset_id FROM demo_user.OL_DATASET WHERE dataset_id = ?`. Return `nil, nil` if no rows.
    - Parse database and table from datasetID using parseDatasetName.
    - Query DBC.TablesV for view SQL and table comment:
      ```sql
      SELECT t.TableKind, TRIM(t.CommentString), t.RequestText, t.RequestTxtOverFlow
      FROM DBC.TablesV t
      WHERE t.DatabaseName = ? AND t.TableName = ?
      ```
      Note: RequestTxtOverFlow may not exist. If the query fails due to this column, retry without it and set Truncated based on whether RequestText length equals 12500.
    - Map TableKind same as statistics.
    - For views (TableKind='V'), set ViewSQL from TRIM(RequestText). Set Truncated from RequestTxtOverFlow if available, or check `len(RequestText) >= 12500`.
    - Query DBC.ColumnsJQV for column comments:
      ```sql
      SELECT TRIM(ColumnName), TRIM(CommentString)
      FROM DBC.ColumnsJQV
      WHERE DatabaseName = ? AND TableName = ?
        AND CommentString IS NOT NULL AND TRIM(CommentString) <> ''
      ORDER BY ColumnId
      ```
      If this query fails (DBC permission issue), log the error and continue with empty column comments.
    - Build `map[string]string` of column_name -> comment.
    - Return `*DatasetDDL` with populated fields.

    Important: Add `"strings"` to imports in openlineage_repo.go if not already present. The `parseDatasetName` function needs `strings.LastIndex` and `strings.Index`.
  </action>
  <verify>
    Run `cd /Users/Daniel.Tehan/Code/lineage/lineage-api && go build ./...` -- must compile with no errors.
    Run `cd /Users/Daniel.Tehan/Code/lineage/lineage-api && go vet ./...` -- must pass.
  </verify>
  <done>
    - DatasetStatistics and DatasetDDL structs exist in entities.go
    - GetDatasetStatistics and GetDatasetDDL methods on OpenLineageRepository interface
    - DTO response types exist in dto.go
    - Service methods call repo.GetDataset first (existence check), then repo.GetDatasetStatistics/GetDatasetDDL
    - Teradata repo queries DBC.TablesV, DBC.TableStatsV, DBC.TableSizeV, DBC.ColumnsJQV
    - All DBC queries use parameterized values (no string interpolation of database/table names)
    - Go project compiles successfully
  </done>
</task>

<task type="auto">
  <name>Task 2: HTTP handlers, router registration, and mock repository</name>
  <files>
    lineage-api/internal/adapter/inbound/http/openlineage_handlers.go
    lineage-api/internal/adapter/inbound/http/router.go
    lineage-api/internal/domain/mocks/repositories.go
  </files>
  <action>
    **1. Add handler methods to openlineage_handlers.go** (append after GetLineageGraph handler):

    Add `GetDatasetStatistics` handler:
    - Extract `datasetId` from URL param: `chi.URLParam(r, "datasetId")`
    - Call `h.service.GetDatasetStatistics(ctx, datasetID)`
    - On error: log with slog.ErrorContext following exact same pattern as GetDataset handler (include request_id, dataset_id, error, stack, method, path). Return `respondError(w, r, http.StatusInternalServerError, "Internal server error")`. DO NOT include any DBC-specific error details in the response (API-05 security requirement).
    - On nil result: `respondError(w, r, http.StatusNotFound, "Dataset not found")`
    - On success: `respondJSON(w, http.StatusOK, stats)`

    Add `GetDatasetDDL` handler:
    - Same pattern as GetDatasetStatistics handler.
    - Extract datasetId, call service, handle error/nil/success identically.

    **2. Register routes in router.go**:

    Inside the `r.Route("/api/v2/openlineage", ...)` block, add two new routes AFTER the existing `r.Get("/datasets/{datasetId}", olHandler.GetDataset)` line:

    ```go
    r.Get("/datasets/{datasetId}/statistics", olHandler.GetDatasetStatistics)
    r.Get("/datasets/{datasetId}/ddl", olHandler.GetDatasetDDL)
    ```

    IMPORTANT: These routes MUST be registered AFTER `r.Get("/datasets/search", ...)` and AFTER `r.Get("/datasets/{datasetId}", ...)` to avoid Chi routing conflicts. The existing order already has `/datasets/search` before `/datasets/{datasetId}`, so place the new routes after the existing `{datasetId}` route.

    **3. Update mock repository in repositories.go**:

    Add a `MockOpenLineageRepository` struct to `mocks/repositories.go` (there isn't one yet -- the current mock file only has MockAssetRepository, MockLineageRepository, MockSearchRepository, MockCacheRepository):

    ```go
    // MockOpenLineageRepository is a mock implementation of domain.OpenLineageRepository.
    type MockOpenLineageRepository struct {
        mu sync.RWMutex

        // Data
        Namespaces []domain.OpenLineageNamespace
        Datasets   []domain.OpenLineageDataset
        Fields     []domain.OpenLineageField
        Jobs       []domain.OpenLineageJob
        Runs       []domain.OpenLineageRun
        Lineages   []domain.OpenLineageColumnLineage
        Statistics map[string]*domain.DatasetStatistics
        DDLData    map[string]*domain.DatasetDDL
        GraphData  map[string]*domain.OpenLineageGraph

        // Error injection
        GetNamespaceErr          error
        GetNamespaceByURIErr     error
        ListNamespacesErr        error
        GetDatasetErr            error
        ListDatasetsErr          error
        SearchDatasetsErr        error
        GetFieldErr              error
        ListFieldsErr            error
        GetJobErr                error
        ListJobsErr              error
        GetRunErr                error
        ListRunsErr              error
        GetColumnLineageErr      error
        GetColumnLineageGraphErr error
        GetDatasetStatisticsErr  error
        GetDatasetDDLErr         error
    }
    ```

    Add `NewMockOpenLineageRepository` constructor initializing all maps.

    Implement ALL methods of `domain.OpenLineageRepository` interface on MockOpenLineageRepository:
    - For GetNamespace: iterate Namespaces, match by ID, return &ns or nil, nil
    - For GetNamespaceByURI: iterate Namespaces, match by URI
    - For ListNamespaces: return Namespaces slice
    - For GetDataset: iterate Datasets, match by ID
    - For ListDatasets: filter by namespaceID, apply limit/offset pagination, return count
    - For SearchDatasets: filter by name containing query
    - For GetField: iterate Fields, match by ID
    - For ListFields: filter by datasetID
    - For GetJob, ListJobs, GetRun, ListRuns: similar patterns
    - For GetColumnLineage: return Lineages filtered by datasetID+fieldName
    - For GetColumnLineageGraph: return GraphData[datasetID+"/"+fieldName] or empty graph
    - For GetDatasetStatistics: return Statistics[datasetID] or nil, nil
    - For GetDatasetDDL: return DDLData[datasetID] or nil, nil

    Each method checks its error injection field first and returns that error if set.

    Add `var _ domain.OpenLineageRepository = (*MockOpenLineageRepository)(nil)` for compile-time interface check.
  </action>
  <verify>
    Run `cd /Users/Daniel.Tehan/Code/lineage/lineage-api && go build ./...` -- must compile.
    Run `cd /Users/Daniel.Tehan/Code/lineage/lineage-api && go vet ./...` -- must pass.
    Run `cd /Users/Daniel.Tehan/Code/lineage/lineage-api && go test ./...` -- all existing tests must pass.
  </verify>
  <done>
    - GetDatasetStatistics and GetDatasetDDL handlers in openlineage_handlers.go
    - Both handlers log errors with slog.ErrorContext and return generic "Internal server error"
    - Both handlers return 404 for nil results
    - Routes registered in router.go at /datasets/{datasetId}/statistics and /datasets/{datasetId}/ddl
    - MockOpenLineageRepository implements full domain.OpenLineageRepository interface
    - Mock includes Statistics and DDLData maps plus error injection for new methods
    - All existing tests still pass
  </done>
</task>

</tasks>

<verification>
1. `cd /Users/Daniel.Tehan/Code/lineage/lineage-api && go build ./...` compiles clean
2. `cd /Users/Daniel.Tehan/Code/lineage/lineage-api && go vet ./...` passes
3. `cd /Users/Daniel.Tehan/Code/lineage/lineage-api && go test ./...` all tests pass
4. Grep for `respondError.*Internal server error` in both new handlers confirms security pattern
5. Grep for `GetDatasetStatistics` appears in entities, repository, repo, service, handlers, mocks
6. Grep for `DBC.TablesV` appears in openlineage_repo.go
7. router.go contains both `/datasets/{datasetId}/statistics` and `/datasets/{datasetId}/ddl`
</verification>

<success_criteria>
- Go project compiles and all existing tests pass
- Two new endpoints registered in router
- Domain entities, repository interface, service, handlers, repo, mocks all connected
- Statistics endpoint queries DBC.TablesV + DBC.TableStatsV + DBC.TableSizeV
- DDL endpoint queries DBC.TablesV + DBC.ColumnsJQV
- Error handling follows existing security pattern (generic 500, specific slog)
- 404 returned for missing datasets (not 500)
</success_criteria>

<output>
After completion, create `.planning/phases/20-backend-statistics-&-ddl-api/20-01-SUMMARY.md`
</output>
